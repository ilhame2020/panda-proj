
# ğŸ“¦ Morocco E-Commerce Data Cleaning & Analysis  
### **Comprehensive Preprocessing Pipeline (Python Â· Pandas Â· VS Code Â· Jupyter Notebook)**  

This project provides a **fully modular, production-ready preprocessing pipeline** for cleaning, validating, profiling, transforming, and analyzing an e-commerce dataset from Morocco.  
The work follows a structured approach inspired by best practices in **Data Engineering**, **Data Quality**, and **Exploratory Data Analysis (EDA)**.

---

## ğŸ“ Project Structure  

```
tppandas/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ morocco_ecommerce.xlsx
â”‚   â””â”€â”€ (other raw filesâ€¦)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ pipeline_notebook.ipynb   # Main notebook with the full workflow
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ s1_loading/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ loading.py            # Load data, inspect_data()
â”‚   â”‚
â”‚   â”œâ”€â”€ s2_profiling/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ profiling.py          # Full profiling: types, dates, inconsistencies
â”‚   â”‚
â”‚   â”œâ”€â”€ s3_cleaning/
â”‚   â”‚   â”œâ”€â”€ cleaning_missing_values.py
â”‚   â”‚   â”œâ”€â”€ cleaning_duplicates.py
â”‚   â”‚   â”œâ”€â”€ cleaning_type_fixing.py
â”‚   â”‚   â”œâ”€â”€ string_cleaning.py
â”‚   â”‚   â”œâ”€â”€ region_city_fixing.py
â”‚   â”‚   â”œâ”€â”€ amount_completion.py
â”‚   â”‚   â””â”€â”€ date_fixing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ s4_features/
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # date features, aggregates, new variables
â”‚   â”‚
â”‚   â”œâ”€â”€ s5_analysis/
â”‚   â”‚   â”œâ”€â”€ descriptive_stats.py
â”‚   â”‚   â”œâ”€â”€ grouping_kpis.py
â”‚   â”‚   â””â”€â”€ timeseries_analysis.py
â”‚   â”‚
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ full_preprocessing.py   # Final orchestrated pipeline
â”‚       â””â”€â”€ __init__.py
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ cleaned_dataset.csv
    â”œâ”€â”€ cleaned_dataset.xlsx
    â””â”€â”€ (generated plotsâ€¦)
```

---

# ğŸ¯ Project Goals  

### âœ” Clean real-world messy dataset  
- Missing values  
- Duplicates  
- Incorrect types  
- Corrupted numeric fields (â€œfreeâ€, â€œtwentyâ€, â€œNaNâ€, etc.)  
- Incorrect city/region combinations  
- Inconsistent dates  

### âœ” Generate a full profiling report  
- Type inference  
- Numeric anomalies  
- Inconsistent text  
- Date validity  
- Suspicious values  

### âœ” Build reusable cleaning modules  
Each cleaning function supports **test_mode=True** for debugging and transparency.

### âœ” Provide complete analysis  
- Statistical metrics  
- Regional KPIs  
- Product KPIs  
- Time-series revenue analysis  

### âœ” Export the final cleaned dataset  
The pipeline auto-detects the file format and exports with the same name plus `_cleaned`.

---

# ğŸ§© Pipeline Overview  

## **1ï¸âƒ£ Loading & Inspection**  
- Load CSV, Excel, or JSON  
- Display shape, info(), head()  
- Column types overview  
- Basic validation rules  

## **2ï¸âƒ£ Profiling**  
- Invalid dates  
- Numeric coercion test  
- Text inconsistencies  
- Value distribution and uniqueness  
- Outlier detection preview  
- Structural inspection (df.describe(include="all"))  

## **3ï¸âƒ£ Cleaning**  
Includes modules for:  

âœ” Missing values  
âœ” Duplicate removal  
âœ” Numeric type fixing  
âœ” Number-words conversion  
âœ” Free text â†’ 0 replacement  
âœ” City & region harmonization  
âœ” Completing missing `quantity`, `unit_price`, `total_amount` using rules  
âœ” Detect & mark outliers (IQR)  

Every function includes:  
```python
test_mode=True  # prints before/after preview
```

## **4ï¸âƒ£ Feature Engineering**  
- Year, month, day  
- Weekday  
- Revenue aggregates  
- Order size metrics  

## **5ï¸âƒ£ Analysis**  
- Descriptive statistics  
- KPI per region and per category  
- Top products  
- Time series (monthly revenue & AOV)  
- Trend visualization (Matplotlib)  

---

# ğŸš€ How to Run the Full Pipeline  

### **Option A â€” Use the Jupyter Notebook**  
Open:

```
notebooks/pipeline_notebook.ipynb
```

and run all cells.

### **Option B â€” Run the full pipeline script**

```python
from preprocessing.pipeline.full_preprocessing import full_preprocessing

cleaned_df = full_preprocessing("data/morocco_ecommerce.xlsx")
```

This automatically:

âœ” Loads  
âœ” Profiles  
âœ” Cleans  
âœ” Generates features  
âœ” Performs analysis  
âœ” Saves cleaned file in `/results/`

---

# ğŸ“¤ Export of Cleaned Data  
At the end of the pipeline, the script auto-detects your file type:

| Input Format | Output Format |
|--------------|----------------|
| `.csv`       | `*_cleaned.csv` |
| `.xlsx`      | `*_cleaned.xlsx` |
| `.json`      | `*_cleaned.json` |

Example:

```
data/morocco_ecommerce.xlsx â†’ results/morocco_ecommerce_cleaned.xlsx
```

---

# ğŸ§ª Test Mode (Debugging)  

Nearly all functions include:

```python
test_mode=True
```

which prints:

- Before cleaning  
- After cleaning  
- Found invalid values  
- Replacements  
- Statistics & checks  

Example:

```python
df = clean_numeric_column(df, "unit_price", test_mode=True)
```

---

# ğŸ–¼ Visual Outputs  

Generated plots include:

- ğŸ“ˆ Monthly revenue trend  
- ğŸ§® KPI summary tables  
- ğŸ—º Revenue by region  
- ğŸ›’ Top product revenue  

Saved automatically in:  
```
results/
```

---

# ğŸ“Œ Requirements  

- Python 3.10+
- pandas
- numpy
- matplotlib
- openpyxl (for Excel export)
- Jupyter Notebook / VS Code

Install:

```bash
pip install pandas numpy matplotlib openpyxl
```

---

# ğŸ Conclusion  

This project gives you:

âœ¨ A **complete, modular, reusable** data cleaning and analysis framework  
âœ¨ Industrial-level structure with **separated concerns**  
âœ¨ Debugging-friendly functions with `test_mode`  
âœ¨ A final notebook for storytelling and exploration  
âœ¨ A pipeline you can extend for larger datasets or ML tasks  
